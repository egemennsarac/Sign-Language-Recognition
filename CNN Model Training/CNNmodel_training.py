# -*- coding: utf-8 -*-
"""training_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CiK9MUsuUMniHecqKDDIdc-hNCxA1UZK

**1.Import Libraries**
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from tensorflow.keras import models, layers, optimizers, regularizers, activations
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications import VGG16, VGG19
from keras.models import Sequential
from tensorflow.keras.optimizers import SGD
from keras.models import load_model
from keras.utils import np_utils
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Dropout
from tensorflow.keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
import pickle

import numpy as np
import cv2
import pandas as pd
from PIL import Image
import os , sys
import matplotlib.pyplot as plt
import seaborn as sns
from skimage.io import imread  
from skimage.transform import resize  

from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils.class_weight import compute_class_weight

from sklearn.model_selection import train_test_split 
from sklearn.metrics import confusion_matrix 

from skimage.segmentation import mark_boundaries

print(tf.__version__)

"""**2.Import Drive Files**"""

from google.colab import drive
drive.mount('/content/drive')

from glob import glob
train_path = '/content/drive/MyDrive/ASLDataset/train'
valid_path = '/content/drive/MyDrive/ASLDataset/validation'

numOfClasses = len(glob('/content/drive/MyDrive/ASLDataset/train/*'))
print(numOfClasses)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size=36
epochs=30
IMG_SIZE = 512


train_datagen = ImageDataGenerator(rescale = 1/255.0,
                                   rotation_range=30,
                                   zoom_range=0.4,
                                   horizontal_flip=True
                                  )

test_datagen = ImageDataGenerator(rescale=1./255)


train_generator = train_datagen.flow_from_directory(
                                                    train_path,
                                                    target_size=(IMG_SIZE, IMG_SIZE),  
                                                    batch_size=batch_size,
                                                    class_mode='categorical',
                                                    )
valid_generator = test_datagen.flow_from_directory(
                                                    valid_path,
                                                    target_size=(IMG_SIZE, IMG_SIZE),
                                                    batch_size=batch_size,
                                                    class_mode='categorical',
                                                  )

(X_train , y_train) = next(train_generator)
(X_val , y_val) = next(valid_generator)
y_train = keras.utils.to_categorical(y_train , num_classes=numOfClasses, dtype='float32')
y_val = keras.utils.to_categorical(y_val , num_classes=numOfClasses, dtype='float32')

print(y_train[:20])
print(y_train.shape)
train_generator.class_indices

print(X_train.shape)
print(y_train.shape)
print(X_val.shape)
print(y_val.shape)

#Plotting the images...
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 10, figsize=(30,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()
plotImages(X_train)

model = Sequential()

model.add(Conv2D(32, 3, 3, padding='same', activation='relu',input_shape=X_train.shape[1:]))

model.add(Conv2D(32, 3, 3, activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, 3, 3, activation='relu', padding='same'))

model.add(Conv2D(64, 3, 3, activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(numOfClasses, activation='softmax'))
    
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

history = model.fit(train_generator,
                    steps_per_epoch=train_generator.samples//batch_size,    
                    validation_data= valid_generator,
                    validation_steps=valid_generator.samples//batch_size,
                    epochs=epochs,
                    verbose=1
                    )

# Model evaluation
scores_train = model.evaluate(train_generator,verbose=1)
scores_validation = model.evaluate(valid_generator,verbose=1)
print("Train Accuracy: %.2f%%" % (scores_train[1]*100))
print("Validation Accuracy: %.2f%%" % (scores_validation[1]*100))
#For plotting Accuracy and Loss

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
LearningCurve(history)

model.save('/content/drive/MyDrive/MyCNN/cnnModel.h5')

model.save('/content/drive/MyDrive/MyCNN/cnnModel_tf', save_format = 'tf')

history2 = model.fit(train_generator,
                    steps_per_epoch=train_generator.samples//batch_size,    
                    validation_data= valid_generator,
                    validation_steps=valid_generator.samples//batch_size,
                    epochs=epochs,
                    verbose=1
                    )

model.save('/content/drive/MyDrive/MyCNN/cnnModel1.h5')

model.save('/content/drive/MyDrive/MyCNN/cnnModel1_tf', save_format = 'tf')

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for accuracy
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()